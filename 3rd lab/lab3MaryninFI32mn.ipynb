{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "04b0c9aa",
   "metadata": {},
   "source": [
    "# Лабораторна робота №3:Знайомство з нейромережами. Маринін Іван Павло Ігорович, ФІ-32мн"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33d44b63",
   "metadata": {},
   "source": [
    "Датасет: https://www.kaggle.com/datasets/gabrielsantello/medical-malpractice-insurance-dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "518ea045",
   "metadata": {},
   "source": [
    "1. Повнозв'язані нейронні мережі"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ceac46cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a851acbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 55158 entries, 0 to 79209\n",
      "Data columns (total 8 columns):\n",
      " #   Column            Non-Null Count  Dtype \n",
      "---  ------            --------------  ----- \n",
      " 0   Amount            55158 non-null  int64 \n",
      " 1   Severity          55158 non-null  int64 \n",
      " 2   Age               55158 non-null  int64 \n",
      " 3   Private Attorney  55158 non-null  int64 \n",
      " 4   Marital Status    55158 non-null  int64 \n",
      " 5   Specialty         55158 non-null  object\n",
      " 6   Insurance         55158 non-null  object\n",
      " 7   Gender            55158 non-null  object\n",
      "dtypes: int64(5), object(3)\n",
      "memory usage: 3.8+ MB\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 55158 entries, 0 to 79209\n",
      "Data columns (total 9 columns):\n",
      " #   Column                          Non-Null Count  Dtype\n",
      "---  ------                          --------------  -----\n",
      " 0   Amount                          55158 non-null  int64\n",
      " 1   Severity                        55158 non-null  int64\n",
      " 2   Age                             55158 non-null  int64\n",
      " 3   Private Attorney                55158 non-null  int64\n",
      " 4   Marital Status                  55158 non-null  int64\n",
      " 5   Insurance_No Insurance          55158 non-null  uint8\n",
      " 6   Insurance_Private               55158 non-null  uint8\n",
      " 7   Insurance_Workers Compensation  55158 non-null  uint8\n",
      " 8   Gender_Male                     55158 non-null  uint8\n",
      "dtypes: int64(5), uint8(4)\n",
      "memory usage: 2.7 MB\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('medicalmalpractice.csv', delimiter=',')\n",
    "df = df[df.apply(lambda x: x.ne('Unknown').all(), axis=1)]\n",
    "df.info()\n",
    "df = df.drop(columns=['Specialty'])\n",
    "df = pd.get_dummies(df, drop_first=True)\n",
    "df.info()\n",
    "df.to_csv('medicalmalpractice1.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8161ac46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class '_io.TextIOWrapper'>\n",
      "HEADER: Amount,Severity,Age,Private Attorney,Marital Status,Insurance_No Insurance,Insurance_Private,Insurance_Workers Compensation,Gender_Male\n",
      "EXAMPLE FEATURES: [57041.0, 7.0, 62.0, 1.0, 2.0, 0.0, 1.0, 0.0]\n",
      "features.shape: (55158, 8)\n",
      "targets.shape: (55158, 1)\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import numpy as np\n",
    "\n",
    "fname = \"medicalmalpractice1.csv\"\n",
    "\n",
    "all_features = []\n",
    "all_targets = []\n",
    "with open(fname) as f:\n",
    "    print(type(f))\n",
    "    for i, line in enumerate(f):\n",
    "        if i == 0:\n",
    "            print(\"HEADER:\", line.strip())\n",
    "            continue\n",
    "        fields = line.strip().split(\",\")\n",
    "        all_features.append([float(v.replace('\"', \"\")) for v in fields[:-1]])\n",
    "        all_targets.append([int(fields[-1].replace('\"', \"\"))])\n",
    "        if i == 1:\n",
    "            print(\"EXAMPLE FEATURES:\", all_features[-1])\n",
    "\n",
    "features = np.array(all_features, dtype=\"float32\")\n",
    "targets = np.array(all_targets, dtype=\"uint8\")\n",
    "print(\"features.shape:\", features.shape)\n",
    "print(\"targets.shape:\", targets.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "338c1d9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training samples: 44127\n",
      "Number of validation samples: 11031\n"
     ]
    }
   ],
   "source": [
    "num_val_samples = int(len(features) * 0.2)\n",
    "train_features = features[:-num_val_samples]\n",
    "train_targets = targets[:-num_val_samples]\n",
    "val_features = features[-num_val_samples:]\n",
    "val_targets = targets[-num_val_samples:]\n",
    "\n",
    "print(\"Number of training samples:\", len(train_features))\n",
    "print(\"Number of validation samples:\", len(val_features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7253b109",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of positive samples in training data: 12772 (28.94% of total)\n"
     ]
    }
   ],
   "source": [
    "counts = np.bincount(train_targets[:, 0])\n",
    "print(\n",
    "    \"Number of positive samples in training data: {} ({:.2f}% of total)\".format(\n",
    "        counts[1], 100 * float(counts[1]) / len(train_targets)\n",
    "    )\n",
    ")\n",
    "\n",
    "weight_for_0 = 1.0 / counts[0]\n",
    "weight_for_1 = 1.0 / counts[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4e7c4a91",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean = np.mean(train_features, axis=0)\n",
    "train_features -= mean\n",
    "val_features -= mean\n",
    "std = np.std(train_features, axis=0)\n",
    "train_features /= std\n",
    "val_features /= std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ce193e97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From D:\\Anaconda\\lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "WARNING:tensorflow:From D:\\Anaconda\\lib\\site-packages\\keras\\src\\backend.py:1398: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 256)               2304      \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 256)               65792     \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 256)               0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 256)               65792     \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 256)               0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 1)                 257       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 134145 (524.00 KB)\n",
      "Trainable params: 134145 (524.00 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "\n",
    "model = keras.Sequential(\n",
    "    [\n",
    "        keras.Input(shape=train_features.shape[1:]),\n",
    "        keras.layers.Dense(256, activation=\"relu\"),\n",
    "        keras.layers.Dense(256, activation=\"relu\"),\n",
    "        keras.layers.Dropout(0.3),\n",
    "        keras.layers.Dense(256, activation=\"relu\"),\n",
    "        keras.layers.Dropout(0.3),\n",
    "        keras.layers.Dense(1, activation=\"sigmoid\"),\n",
    "    ]\n",
    ")\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c8101325",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "WARNING:tensorflow:From D:\\Anaconda\\lib\\site-packages\\keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
      "\n",
      "22/22 - 3s - loss: 2.8882e-05 - fn: 3761.0000 - fp: 13531.0000 - tn: 17824.0000 - tp: 9011.0000 - precision: 0.3997 - recall: 0.7055 - val_loss: 0.5509 - val_fn: 755.0000 - val_fp: 2619.0000 - val_tn: 5291.0000 - val_tp: 2366.0000 - val_precision: 0.4746 - val_recall: 0.7581 - 3s/epoch - 156ms/step\n",
      "Epoch 2/30\n",
      "22/22 - 1s - loss: 2.3305e-05 - fn: 2469.0000 - fp: 10194.0000 - tn: 21161.0000 - tp: 10303.0000 - precision: 0.5027 - recall: 0.8067 - val_loss: 0.4608 - val_fn: 425.0000 - val_fp: 2351.0000 - val_tn: 5559.0000 - val_tp: 2696.0000 - val_precision: 0.5342 - val_recall: 0.8638 - 912ms/epoch - 41ms/step\n",
      "Epoch 3/30\n",
      "22/22 - 1s - loss: 2.0394e-05 - fn: 2008.0000 - fp: 8634.0000 - tn: 22721.0000 - tp: 10764.0000 - precision: 0.5549 - recall: 0.8428 - val_loss: 0.4221 - val_fn: 440.0000 - val_fp: 1982.0000 - val_tn: 5928.0000 - val_tp: 2681.0000 - val_precision: 0.5750 - val_recall: 0.8590 - 912ms/epoch - 41ms/step\n",
      "Epoch 4/30\n",
      "22/22 - 1s - loss: 1.8396e-05 - fn: 1769.0000 - fp: 7754.0000 - tn: 23601.0000 - tp: 11003.0000 - precision: 0.5866 - recall: 0.8615 - val_loss: 0.3737 - val_fn: 530.0000 - val_fp: 1627.0000 - val_tn: 6283.0000 - val_tp: 2591.0000 - val_precision: 0.6143 - val_recall: 0.8302 - 939ms/epoch - 43ms/step\n",
      "Epoch 5/30\n",
      "22/22 - 1s - loss: 1.7163e-05 - fn: 1642.0000 - fp: 7346.0000 - tn: 24009.0000 - tp: 11130.0000 - precision: 0.6024 - recall: 0.8714 - val_loss: 0.3780 - val_fn: 301.0000 - val_fp: 1920.0000 - val_tn: 5990.0000 - val_tp: 2820.0000 - val_precision: 0.5949 - val_recall: 0.9036 - 890ms/epoch - 40ms/step\n",
      "Epoch 6/30\n",
      "22/22 - 1s - loss: 1.6333e-05 - fn: 1555.0000 - fp: 7071.0000 - tn: 24284.0000 - tp: 11217.0000 - precision: 0.6134 - recall: 0.8782 - val_loss: 0.3945 - val_fn: 229.0000 - val_fp: 2088.0000 - val_tn: 5822.0000 - val_tp: 2892.0000 - val_precision: 0.5807 - val_recall: 0.9266 - 897ms/epoch - 41ms/step\n",
      "Epoch 7/30\n",
      "22/22 - 1s - loss: 1.5898e-05 - fn: 1330.0000 - fp: 7137.0000 - tn: 24218.0000 - tp: 11442.0000 - precision: 0.6159 - recall: 0.8959 - val_loss: 0.3441 - val_fn: 290.0000 - val_fp: 1707.0000 - val_tn: 6203.0000 - val_tp: 2831.0000 - val_precision: 0.6238 - val_recall: 0.9071 - 920ms/epoch - 42ms/step\n",
      "Epoch 8/30\n",
      "22/22 - 1s - loss: 1.5379e-05 - fn: 1278.0000 - fp: 6891.0000 - tn: 24464.0000 - tp: 11494.0000 - precision: 0.6252 - recall: 0.8999 - val_loss: 0.3325 - val_fn: 361.0000 - val_fp: 1597.0000 - val_tn: 6313.0000 - val_tp: 2760.0000 - val_precision: 0.6335 - val_recall: 0.8843 - 987ms/epoch - 45ms/step\n",
      "Epoch 9/30\n",
      "22/22 - 1s - loss: 1.5092e-05 - fn: 1323.0000 - fp: 6629.0000 - tn: 24726.0000 - tp: 11449.0000 - precision: 0.6333 - recall: 0.8964 - val_loss: 0.3402 - val_fn: 246.0000 - val_fp: 1800.0000 - val_tn: 6110.0000 - val_tp: 2875.0000 - val_precision: 0.6150 - val_recall: 0.9212 - 1s/epoch - 49ms/step\n",
      "Epoch 10/30\n",
      "22/22 - 1s - loss: 1.4818e-05 - fn: 1149.0000 - fp: 6796.0000 - tn: 24559.0000 - tp: 11623.0000 - precision: 0.6310 - recall: 0.9100 - val_loss: 0.3272 - val_fn: 308.0000 - val_fp: 1648.0000 - val_tn: 6262.0000 - val_tp: 2813.0000 - val_precision: 0.6306 - val_recall: 0.9013 - 1s/epoch - 46ms/step\n",
      "Epoch 11/30\n",
      "22/22 - 1s - loss: 1.4690e-05 - fn: 1249.0000 - fp: 6610.0000 - tn: 24745.0000 - tp: 11523.0000 - precision: 0.6355 - recall: 0.9022 - val_loss: 0.3507 - val_fn: 198.0000 - val_fp: 1900.0000 - val_tn: 6010.0000 - val_tp: 2923.0000 - val_precision: 0.6061 - val_recall: 0.9366 - 1s/epoch - 54ms/step\n",
      "Epoch 12/30\n",
      "22/22 - 1s - loss: 1.4394e-05 - fn: 1128.0000 - fp: 6670.0000 - tn: 24685.0000 - tp: 11644.0000 - precision: 0.6358 - recall: 0.9117 - val_loss: 0.3156 - val_fn: 296.0000 - val_fp: 1569.0000 - val_tn: 6341.0000 - val_tp: 2825.0000 - val_precision: 0.6429 - val_recall: 0.9052 - 970ms/epoch - 44ms/step\n",
      "Epoch 13/30\n",
      "22/22 - 1s - loss: 1.4122e-05 - fn: 1118.0000 - fp: 6512.0000 - tn: 24843.0000 - tp: 11654.0000 - precision: 0.6415 - recall: 0.9125 - val_loss: 0.3403 - val_fn: 167.0000 - val_fp: 1928.0000 - val_tn: 5982.0000 - val_tp: 2954.0000 - val_precision: 0.6051 - val_recall: 0.9465 - 876ms/epoch - 40ms/step\n",
      "Epoch 14/30\n",
      "22/22 - 1s - loss: 1.3962e-05 - fn: 1099.0000 - fp: 6432.0000 - tn: 24923.0000 - tp: 11673.0000 - precision: 0.6447 - recall: 0.9140 - val_loss: 0.3091 - val_fn: 274.0000 - val_fp: 1606.0000 - val_tn: 6304.0000 - val_tp: 2847.0000 - val_precision: 0.6393 - val_recall: 0.9122 - 918ms/epoch - 42ms/step\n",
      "Epoch 15/30\n",
      "22/22 - 1s - loss: 1.3874e-05 - fn: 1085.0000 - fp: 6411.0000 - tn: 24944.0000 - tp: 11687.0000 - precision: 0.6458 - recall: 0.9150 - val_loss: 0.2987 - val_fn: 305.0000 - val_fp: 1496.0000 - val_tn: 6414.0000 - val_tp: 2816.0000 - val_precision: 0.6531 - val_recall: 0.9023 - 921ms/epoch - 42ms/step\n",
      "Epoch 16/30\n",
      "22/22 - 1s - loss: 1.3706e-05 - fn: 1152.0000 - fp: 6278.0000 - tn: 25077.0000 - tp: 11620.0000 - precision: 0.6492 - recall: 0.9098 - val_loss: 0.3209 - val_fn: 207.0000 - val_fp: 1737.0000 - val_tn: 6173.0000 - val_tp: 2914.0000 - val_precision: 0.6265 - val_recall: 0.9337 - 894ms/epoch - 41ms/step\n",
      "Epoch 17/30\n",
      "22/22 - 1s - loss: 1.3640e-05 - fn: 1110.0000 - fp: 6375.0000 - tn: 24980.0000 - tp: 11662.0000 - precision: 0.6466 - recall: 0.9131 - val_loss: 0.3133 - val_fn: 201.0000 - val_fp: 1724.0000 - val_tn: 6186.0000 - val_tp: 2920.0000 - val_precision: 0.6288 - val_recall: 0.9356 - 887ms/epoch - 40ms/step\n",
      "Epoch 18/30\n",
      "22/22 - 1s - loss: 1.3586e-05 - fn: 1066.0000 - fp: 6375.0000 - tn: 24980.0000 - tp: 11706.0000 - precision: 0.6474 - recall: 0.9165 - val_loss: 0.3051 - val_fn: 197.0000 - val_fp: 1624.0000 - val_tn: 6286.0000 - val_tp: 2924.0000 - val_precision: 0.6429 - val_recall: 0.9369 - 882ms/epoch - 40ms/step\n",
      "Epoch 19/30\n",
      "22/22 - 1s - loss: 1.3223e-05 - fn: 1058.0000 - fp: 6137.0000 - tn: 25218.0000 - tp: 11714.0000 - precision: 0.6562 - recall: 0.9172 - val_loss: 0.2953 - val_fn: 302.0000 - val_fp: 1412.0000 - val_tn: 6498.0000 - val_tp: 2819.0000 - val_precision: 0.6663 - val_recall: 0.9032 - 860ms/epoch - 39ms/step\n",
      "Epoch 20/30\n",
      "22/22 - 1s - loss: 1.3164e-05 - fn: 1072.0000 - fp: 6010.0000 - tn: 25345.0000 - tp: 11700.0000 - precision: 0.6606 - recall: 0.9161 - val_loss: 0.2945 - val_fn: 254.0000 - val_fp: 1559.0000 - val_tn: 6351.0000 - val_tp: 2867.0000 - val_precision: 0.6478 - val_recall: 0.9186 - 866ms/epoch - 39ms/step\n",
      "Epoch 21/30\n",
      "22/22 - 1s - loss: 1.2975e-05 - fn: 1072.0000 - fp: 5998.0000 - tn: 25357.0000 - tp: 11700.0000 - precision: 0.6611 - recall: 0.9161 - val_loss: 0.2946 - val_fn: 196.0000 - val_fp: 1606.0000 - val_tn: 6304.0000 - val_tp: 2925.0000 - val_precision: 0.6456 - val_recall: 0.9372 - 889ms/epoch - 40ms/step\n",
      "Epoch 22/30\n",
      "22/22 - 1s - loss: 1.3114e-05 - fn: 1030.0000 - fp: 6084.0000 - tn: 25271.0000 - tp: 11742.0000 - precision: 0.6587 - recall: 0.9194 - val_loss: 0.2918 - val_fn: 254.0000 - val_fp: 1518.0000 - val_tn: 6392.0000 - val_tp: 2867.0000 - val_precision: 0.6538 - val_recall: 0.9186 - 855ms/epoch - 39ms/step\n",
      "Epoch 23/30\n",
      "22/22 - 1s - loss: 1.2908e-05 - fn: 980.0000 - fp: 6031.0000 - tn: 25324.0000 - tp: 11792.0000 - precision: 0.6616 - recall: 0.9233 - val_loss: 0.2860 - val_fn: 241.0000 - val_fp: 1487.0000 - val_tn: 6423.0000 - val_tp: 2880.0000 - val_precision: 0.6595 - val_recall: 0.9228 - 987ms/epoch - 45ms/step\n",
      "Epoch 24/30\n",
      "22/22 - 1s - loss: 1.2779e-05 - fn: 1041.0000 - fp: 5784.0000 - tn: 25571.0000 - tp: 11731.0000 - precision: 0.6698 - recall: 0.9185 - val_loss: 0.2941 - val_fn: 204.0000 - val_fp: 1543.0000 - val_tn: 6367.0000 - val_tp: 2917.0000 - val_precision: 0.6540 - val_recall: 0.9346 - 922ms/epoch - 42ms/step\n",
      "Epoch 25/30\n",
      "22/22 - 1s - loss: 1.2549e-05 - fn: 1027.0000 - fp: 5719.0000 - tn: 25636.0000 - tp: 11745.0000 - precision: 0.6725 - recall: 0.9196 - val_loss: 0.2906 - val_fn: 223.0000 - val_fp: 1508.0000 - val_tn: 6402.0000 - val_tp: 2898.0000 - val_precision: 0.6577 - val_recall: 0.9285 - 961ms/epoch - 44ms/step\n",
      "Epoch 26/30\n",
      "22/22 - 1s - loss: 1.2452e-05 - fn: 966.0000 - fp: 5784.0000 - tn: 25571.0000 - tp: 11806.0000 - precision: 0.6712 - recall: 0.9244 - val_loss: 0.2898 - val_fn: 183.0000 - val_fp: 1586.0000 - val_tn: 6324.0000 - val_tp: 2938.0000 - val_precision: 0.6494 - val_recall: 0.9414 - 1s/epoch - 46ms/step\n",
      "Epoch 27/30\n",
      "22/22 - 1s - loss: 1.2378e-05 - fn: 999.0000 - fp: 5585.0000 - tn: 25770.0000 - tp: 11773.0000 - precision: 0.6782 - recall: 0.9218 - val_loss: 0.2849 - val_fn: 195.0000 - val_fp: 1541.0000 - val_tn: 6369.0000 - val_tp: 2926.0000 - val_precision: 0.6550 - val_recall: 0.9375 - 985ms/epoch - 45ms/step\n",
      "Epoch 28/30\n",
      "22/22 - 1s - loss: 1.2432e-05 - fn: 943.0000 - fp: 5704.0000 - tn: 25651.0000 - tp: 11829.0000 - precision: 0.6747 - recall: 0.9262 - val_loss: 0.2849 - val_fn: 215.0000 - val_fp: 1494.0000 - val_tn: 6416.0000 - val_tp: 2906.0000 - val_precision: 0.6605 - val_recall: 0.9311 - 1s/epoch - 47ms/step\n",
      "Epoch 29/30\n",
      "22/22 - 1s - loss: 1.2286e-05 - fn: 946.0000 - fp: 5683.0000 - tn: 25672.0000 - tp: 11826.0000 - precision: 0.6754 - recall: 0.9259 - val_loss: 0.2907 - val_fn: 180.0000 - val_fp: 1552.0000 - val_tn: 6358.0000 - val_tp: 2941.0000 - val_precision: 0.6546 - val_recall: 0.9423 - 1s/epoch - 48ms/step\n",
      "Epoch 30/30\n",
      "22/22 - 1s - loss: 1.2152e-05 - fn: 907.0000 - fp: 5628.0000 - tn: 25727.0000 - tp: 11865.0000 - precision: 0.6783 - recall: 0.9290 - val_loss: 0.2831 - val_fn: 194.0000 - val_fp: 1465.0000 - val_tn: 6445.0000 - val_tp: 2927.0000 - val_precision: 0.6664 - val_recall: 0.9378 - 935ms/epoch - 42ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x1f262ff9520>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics = [\n",
    "    keras.metrics.FalseNegatives(name=\"fn\"),\n",
    "    keras.metrics.FalsePositives(name=\"fp\"),\n",
    "    keras.metrics.TrueNegatives(name=\"tn\"),\n",
    "    keras.metrics.TruePositives(name=\"tp\"),\n",
    "    keras.metrics.Precision(name=\"precision\"),\n",
    "    keras.metrics.Recall(name=\"recall\"),\n",
    "]\n",
    "\n",
    "model.compile(\n",
    "    optimizer=keras.optimizers.Adam(1e-2), loss=\"binary_crossentropy\", metrics=metrics\n",
    ")\n",
    "\n",
    "callbacks = [keras.callbacks.ModelCheckpoint(\"fraud_model_at_epoch_{epoch}.keras\")]\n",
    "class_weight = {0: weight_for_0, 1: weight_for_1}\n",
    "\n",
    "model.fit(\n",
    "    train_features,\n",
    "    train_targets,\n",
    "    batch_size=2048,\n",
    "    epochs=30,\n",
    "    verbose=2,\n",
    "    callbacks=callbacks,\n",
    "    validation_data=(val_features, val_targets),\n",
    "    class_weight=class_weight,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "449833e2",
   "metadata": {},
   "source": [
    "2. Згорткові нейронні мережі"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5e75f82",
   "metadata": {},
   "source": [
    "Датасет із зображеннями: https://www.kaggle.com/datasets/karimabdulnabi/fruit-classification10-class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "46f9fcef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2301 images belonging to 10 classes.\n",
      "Found 1025 images belonging to 10 classes.\n",
      "Shape of x_train: (128, 28, 28, 1)\n",
      "Shape of y_train: (128,)\n",
      "Shape of x_test: (128, 28, 28, 1)\n",
      "Shape of y_test: (128,)\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "train_data_path = \"D:/Універ/магістратура/1 семестр/Data Analysis/lab 3/My_data/train\"\n",
    "test_data_path = \"D:/Універ/магістратура/1 семестр/Data Analysis/lab 3/My_data//test\"\n",
    "\n",
    "img_size = (28, 28)\n",
    "batch_size = 128\n",
    "\n",
    "\n",
    "train_datagen = ImageDataGenerator(rescale=1./255)\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_data_path,\n",
    "    target_size=img_size,\n",
    "    batch_size=batch_size,\n",
    "    class_mode='sparse',  \n",
    "    color_mode='grayscale'\n",
    ")\n",
    "\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "    test_data_path,\n",
    "    target_size=img_size,\n",
    "    batch_size=batch_size,\n",
    "    class_mode='sparse',  \n",
    "    color_mode='grayscale'\n",
    ")\n",
    "\n",
    "num_classes = len(train_generator.class_indices)\n",
    "\n",
    "\n",
    "(x_train, y_train) = train_generator.next()\n",
    "(x_test, y_test) = test_generator.next()\n",
    "\n",
    "print(\"Shape of x_train:\", x_train.shape)\n",
    "print(\"Shape of y_train:\", y_train.shape)\n",
    "print(\"Shape of x_test:\", x_test.shape)\n",
    "print(\"Shape of y_test:\", y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "6ad04067",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)\n",
    "input_shape = (28, 28, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "93e3bcb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_17\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_32 (Conv2D)          (None, 26, 26, 32)        320       \n",
      "                                                                 \n",
      " max_pooling2d_32 (MaxPooli  (None, 13, 13, 32)        0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_33 (Conv2D)          (None, 11, 11, 64)        18496     \n",
      "                                                                 \n",
      " max_pooling2d_33 (MaxPooli  (None, 5, 5, 64)          0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " flatten_16 (Flatten)        (None, 1600)              0         \n",
      "                                                                 \n",
      " dense_31 (Dense)            (None, 128)               204928    \n",
      "                                                                 \n",
      " dense_32 (Dense)            (None, 256)               33024     \n",
      "                                                                 \n",
      " dense_33 (Dense)            (None, 512)               131584    \n",
      "                                                                 \n",
      " dropout_18 (Dropout)        (None, 512)               0         \n",
      "                                                                 \n",
      " dense_34 (Dense)            (None, 10)                5130      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 393482 (1.50 MB)\n",
      "Trainable params: 393482 (1.50 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras import layers\n",
    "\n",
    "model = keras.Sequential(\n",
    "    [\n",
    "        keras.Input(shape=input_shape),\n",
    "        layers.Conv2D(32, kernel_size=(3, 3), activation=\"relu\"),\n",
    "        layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "        layers.Conv2D(64, kernel_size=(3, 3), activation=\"relu\"),\n",
    "        layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "        layers.Flatten(),\n",
    "        layers.Dense(128, activation=\"relu\"),\n",
    "        layers.Dense(256, activation=\"relu\"),\n",
    "        layers.Dense(512, activation=\"relu\"),\n",
    "        layers.Dropout(0.2),\n",
    "        layers.Dense(num_classes, activation=\"softmax\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "e1bf3462",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "1/1 [==============================] - 2s 2s/step - loss: 2.3045 - accuracy: 0.0783 - val_loss: 2.3004 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/15\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 2.2966 - accuracy: 0.1478 - val_loss: 2.2957 - val_accuracy: 0.0769\n",
      "Epoch 3/15\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 2.2858 - accuracy: 0.1565 - val_loss: 2.3105 - val_accuracy: 0.0769\n",
      "Epoch 4/15\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 2.2765 - accuracy: 0.1391 - val_loss: 2.3322 - val_accuracy: 0.0769\n",
      "Epoch 5/15\n",
      "1/1 [==============================] - 0s 113ms/step - loss: 2.2567 - accuracy: 0.1391 - val_loss: 2.3503 - val_accuracy: 0.0769\n",
      "Epoch 6/15\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 2.2518 - accuracy: 0.1478 - val_loss: 2.3352 - val_accuracy: 0.0769\n",
      "Epoch 7/15\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 2.2442 - accuracy: 0.1478 - val_loss: 2.3176 - val_accuracy: 0.0769\n",
      "Epoch 8/15\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 2.2231 - accuracy: 0.1652 - val_loss: 2.2999 - val_accuracy: 0.0769\n",
      "Epoch 9/15\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 2.2112 - accuracy: 0.1652 - val_loss: 2.2728 - val_accuracy: 0.0769\n",
      "Epoch 10/15\n",
      "1/1 [==============================] - 0s 109ms/step - loss: 2.1820 - accuracy: 0.2000 - val_loss: 2.2367 - val_accuracy: 0.0769\n",
      "Epoch 11/15\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 2.1452 - accuracy: 0.2522 - val_loss: 2.2191 - val_accuracy: 0.0769\n",
      "Epoch 12/15\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 2.1299 - accuracy: 0.2174 - val_loss: 2.1694 - val_accuracy: 0.1538\n",
      "Epoch 13/15\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 2.0863 - accuracy: 0.2609 - val_loss: 2.1453 - val_accuracy: 0.1538\n",
      "Epoch 14/15\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 2.0435 - accuracy: 0.2870 - val_loss: 2.1575 - val_accuracy: 0.1538\n",
      "Epoch 15/15\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 2.0075 - accuracy: 0.3130 - val_loss: 2.0768 - val_accuracy: 0.1538\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x1f26f1459d0>"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size = 128\n",
    "epochs = 15\n",
    "\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "\n",
    "model.fit(x_train, y_train, batch_size=batch_size, epochs=epochs, validation_split=0.1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be2484a0",
   "metadata": {},
   "source": [
    "Другий варіант завдання №2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "7322899d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (2591, 28, 28, 1, 1)\n",
      "y_train shape: (2591,)\n",
      "2591 train samples\n",
      "735 test samples\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from zipfile import ZipFile\n",
    "from keras.utils import to_categorical\n",
    "from keras.preprocessing.image import load_img, img_to_array\n",
    "\n",
    "def load_images_from_folder(folder_path):\n",
    "    images = []\n",
    "    labels = []\n",
    "    class_labels = os.listdir(folder_path)\n",
    "    \n",
    "    for class_label in class_labels:\n",
    "        class_path = os.path.join(folder_path, class_label)\n",
    "        \n",
    "        for filename in os.listdir(class_path):\n",
    "            img_path = os.path.join(class_path, filename)\n",
    "            img = load_img(img_path, target_size=(28, 28), color_mode='grayscale')\n",
    "            img_array = img_to_array(img)\n",
    "            img_array /= 255.0  \n",
    "            images.append(img_array)\n",
    "            labels.append(int(class_label)) \n",
    "    return np.array(images), np.array(labels)\n",
    "\n",
    "train_folder_path = \"D:/Універ/магістратура/1 семестр/Data Analysis/lab 3/My_data1/train\"\n",
    "x_train, y_train = load_images_from_folder(train_folder_path)\n",
    "\n",
    "test_folder_path = \"D:/Універ/магістратура/1 семестр/Data Analysis/lab 3/My_data1/test\"\n",
    "x_test, y_test = load_images_from_folder(test_folder_path)\n",
    "\n",
    "x_train = np.expand_dims(x_train, -1)\n",
    "x_test = np.expand_dims(x_test, -1)\n",
    "\n",
    "print(\"x_train shape:\", x_train.shape)\n",
    "print(\"y_train shape:\", y_train.shape)\n",
    "print(x_train.shape[0], \"train samples\")\n",
    "print(x_test.shape[0], \"test samples\")\n",
    "\n",
    "num_classes = len(np.unique(y_train))\n",
    "y_train = to_categorical(y_train-1, num_classes)\n",
    "y_test = to_categorical(y_test-1, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "fd70dfec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_22\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_42 (Conv2D)          (None, 26, 26, 32)        320       \n",
      "                                                                 \n",
      " max_pooling2d_42 (MaxPooli  (None, 13, 13, 32)        0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_43 (Conv2D)          (None, 11, 11, 64)        18496     \n",
      "                                                                 \n",
      " max_pooling2d_43 (MaxPooli  (None, 5, 5, 64)          0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dense_42 (Dense)            (None, 5, 5, 128)         8320      \n",
      "                                                                 \n",
      " dense_43 (Dense)            (None, 5, 5, 256)         33024     \n",
      "                                                                 \n",
      " dense_44 (Dense)            (None, 5, 5, 512)         131584    \n",
      "                                                                 \n",
      " flatten_21 (Flatten)        (None, 12800)             0         \n",
      "                                                                 \n",
      " dropout_23 (Dropout)        (None, 12800)             0         \n",
      "                                                                 \n",
      " dense_45 (Dense)            (None, 10)                128010    \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 319754 (1.22 MB)\n",
      "Trainable params: 319754 (1.22 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = keras.Sequential(\n",
    "    [\n",
    "        keras.Input(shape=input_shape),\n",
    "        layers.Conv2D(32, kernel_size=(3, 3), activation=\"relu\"),\n",
    "        layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "        layers.Conv2D(64, kernel_size=(3, 3), activation=\"relu\"),\n",
    "        layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "        layers.Dense(128, activation=\"relu\"),\n",
    "        layers.Dense(256, activation=\"relu\"),\n",
    "        layers.Dense(512, activation=\"relu\"),\n",
    "        layers.Flatten(),\n",
    "        layers.Dropout(0.5),\n",
    "        layers.Dense(num_classes, activation=\"softmax\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "cc03fce0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "19/19 [==============================] - 4s 125ms/step - loss: 2.2157 - accuracy: 0.1283 - val_loss: 7.5860 - val_accuracy: 0.0038\n",
      "Epoch 2/15\n",
      "19/19 [==============================] - 2s 107ms/step - loss: 2.1343 - accuracy: 0.1832 - val_loss: 6.3321 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/15\n",
      "19/19 [==============================] - 2s 110ms/step - loss: 2.0433 - accuracy: 0.2312 - val_loss: 11.2716 - val_accuracy: 0.0000e+00\n",
      "Epoch 4/15\n",
      "19/19 [==============================] - 2s 106ms/step - loss: 1.9481 - accuracy: 0.2879 - val_loss: 12.8024 - val_accuracy: 0.0000e+00\n",
      "Epoch 5/15\n",
      "19/19 [==============================] - 2s 106ms/step - loss: 1.8528 - accuracy: 0.3299 - val_loss: 12.5501 - val_accuracy: 0.0000e+00\n",
      "Epoch 6/15\n",
      "19/19 [==============================] - 2s 103ms/step - loss: 1.8134 - accuracy: 0.3316 - val_loss: 11.4474 - val_accuracy: 0.0000e+00\n",
      "Epoch 7/15\n",
      "19/19 [==============================] - 2s 113ms/step - loss: 1.7435 - accuracy: 0.3672 - val_loss: 15.6576 - val_accuracy: 0.0000e+00\n",
      "Epoch 8/15\n",
      "19/19 [==============================] - 2s 102ms/step - loss: 1.7479 - accuracy: 0.3737 - val_loss: 12.5507 - val_accuracy: 0.0000e+00\n",
      "Epoch 9/15\n",
      "19/19 [==============================] - 2s 96ms/step - loss: 1.7024 - accuracy: 0.3930 - val_loss: 12.2456 - val_accuracy: 0.0000e+00\n",
      "Epoch 10/15\n",
      "19/19 [==============================] - 2s 91ms/step - loss: 1.6722 - accuracy: 0.4011 - val_loss: 14.4498 - val_accuracy: 0.0038\n",
      "Epoch 11/15\n",
      "19/19 [==============================] - 2s 98ms/step - loss: 1.6140 - accuracy: 0.4204 - val_loss: 14.4629 - val_accuracy: 0.0000e+00\n",
      "Epoch 12/15\n",
      "19/19 [==============================] - 2s 105ms/step - loss: 1.6085 - accuracy: 0.4170 - val_loss: 13.2527 - val_accuracy: 0.0000e+00\n",
      "Epoch 13/15\n",
      "19/19 [==============================] - 2s 121ms/step - loss: 1.5510 - accuracy: 0.4530 - val_loss: 15.1724 - val_accuracy: 0.0000e+00\n",
      "Epoch 14/15\n",
      "19/19 [==============================] - 2s 96ms/step - loss: 1.5287 - accuracy: 0.4535 - val_loss: 14.3105 - val_accuracy: 0.0038\n",
      "Epoch 15/15\n",
      "19/19 [==============================] - 2s 96ms/step - loss: 1.5023 - accuracy: 0.4655 - val_loss: 15.7403 - val_accuracy: 0.0038\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x1f26bf832b0>"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size = 128\n",
    "epochs = 15\n",
    "\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "\n",
    "model.fit(x_train, y_train, batch_size=batch_size, epochs=epochs, validation_split=0.1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3fd3f9b",
   "metadata": {},
   "source": [
    "3. Рекурентні нейронні мережі"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "59f0cad2",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_features = 20000 \n",
    "maxlen = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "59501e57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_25 (InputLayer)       [(None, None)]            0         \n",
      "                                                                 \n",
      " embedding (Embedding)       (None, None, 128)         2560000   \n",
      "                                                                 \n",
      " bidirectional (Bidirection  (None, None, 128)         98816     \n",
      " al)                                                             \n",
      "                                                                 \n",
      " bidirectional_1 (Bidirecti  (None, 128)               98816     \n",
      " onal)                                                           \n",
      "                                                                 \n",
      " dense_46 (Dense)            (None, 1)                 129       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2757761 (10.52 MB)\n",
      "Trainable params: 2757761 (10.52 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "inputs = keras.Input(shape=(None,), dtype=\"int32\")\n",
    "\n",
    "x = layers.Embedding(max_features, 128)(inputs)\n",
    "\n",
    "x = layers.Bidirectional(layers.LSTM(64, return_sequences=True))(x)\n",
    "x = layers.Bidirectional(layers.LSTM(64))(x)\n",
    "\n",
    "outputs = layers.Dense(1, activation=\"sigmoid\")(x)\n",
    "model = keras.Model(inputs, outputs)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "0c6f0cf2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8312 Training sequences\n",
      "2079 Validation sequences\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "df = pd.read_csv('Mental Health Dataset.csv')\n",
    "df = df.dropna(subset=['posts'])\n",
    "\n",
    "train_df, val_df = train_test_split(df, test_size=0.2, random_state=42)\n",
    "\n",
    "tokenizer = keras.preprocessing.text.Tokenizer(num_words=20000)\n",
    "tokenizer.fit_on_texts(train_df[\"posts\"])\n",
    "\n",
    "x_train = tokenizer.texts_to_sequences(train_df[\"posts\"])\n",
    "x_val = tokenizer.texts_to_sequences(val_df[\"posts\"])\n",
    "\n",
    "x_train = pad_sequences(x_train, maxlen=maxlen)\n",
    "x_val = pad_sequences(x_val, maxlen=maxlen)\n",
    "\n",
    "y_train = train_df[\"intensity\"].values\n",
    "y_val = val_df[\"intensity\"].values\n",
    "\n",
    "print(len(x_train), \"Training sequences\")\n",
    "print(len(x_val), \"Validation sequences\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "8456e6d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "260/260 [==============================] - 86s 299ms/step - loss: -15.8637 - accuracy: 0.4182 - val_loss: -26.8060 - val_accuracy: 0.4276\n",
      "Epoch 2/2\n",
      "260/260 [==============================] - 73s 281ms/step - loss: -34.6036 - accuracy: 0.4193 - val_loss: -45.1671 - val_accuracy: 0.4276\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x1f20996fdc0>"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(optimizer=\"adam\", loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\n",
    "model.fit(x_train, y_train, batch_size=32, epochs=2, validation_data=(x_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39c0d620",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
